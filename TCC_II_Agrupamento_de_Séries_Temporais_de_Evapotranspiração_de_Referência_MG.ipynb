{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC II - Agrupamento de Séries Temporais de Evapotranspiração de Referência MG",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fran-ab/Agrupamento-de-Series-Temporais-de-Evapotranspiracao-de-Referencia-MG/blob/main/TCC_II_Agrupamento_de_S%C3%A9ries_Temporais_de_Evapotranspira%C3%A7%C3%A3o_de_Refer%C3%AAncia_MG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afpaIzHsERnk"
      },
      "source": [
        "## **Agrupamento de Séries Temporais de Evapotranspiração de Referência do Estado de Minas Gerais**\n",
        "\n",
        "As **séries temporais** são um tipo comum de dados dinâmicos que podem ser definidas como um conjunto de observações realizadas em sequência ao longo do tempo. A importância de seu **agrupamento** se destaca em:\n",
        "\n",
        "*   Na descoberta de padrões, que podem disponibilizar informações valiosas através do conjunto de dados das séries temporais\n",
        "*   Técnica exploratória e também como sub-rotina em algoritmos de mineração de dados mais complexos, como descoberta de regras, indexação, classificação e detecção de irregularidades\n",
        "\n",
        "A **evapotranspiração** *($ET$)* é a combinação de dois processos, a evaporação e a transpiração. A **evapotranspiração de referência** ($ET_o$) é a taxa de evapotranspiração de uma superfície de referência. Onde a superfície de referência é semelhante a uma grande área de grama verde em crescimento, de altura uniforme, sombreando completamente o solo e com disponibilidade ilimitada de umidade do solo. A $ET_o$ é influenciada apenas por fatores climáticos, portanto, pode ser calculada a partir de dados meteorológicos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHmgVcP1KAr2"
      },
      "source": [
        "## **Objetivos:**\n",
        "\n",
        "Esse trabalho tem como objetivo a comparação dos métodos de agrupamento ***K-means*** e Hierárquico de ***Ward*** para agrupamento de séries temporais de evapotranspiração de referência."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mviigCiwKwHG"
      },
      "source": [
        "## **Base de dados**\n",
        "\n",
        "O conjunto de dados inclui dados diários observados coletados de medidores de chuva, bem como estações meteorológicas convencionais e automáticas do período de **1 de janeiro de 1980 a 31 de dezembro de 2016**. Os dados estão organizados em **5285 arquivos** de formato **.csv** e cada arquivo possui duas colunas: **time (string)** e **ETo (float)**.\n",
        "\n",
        "A base de dados foi extraída do artigo: **Daily gridded meteorological variables in Brazil (1980–2013)**, publicado em 08 de outubro de 2015, pelo International Journal of Climatology. Onde pode ser analisado detalhamente como os foram dados obtidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSl_b6wMsCR"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scipy.stats import zscore\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9wx9FXQU2W"
      },
      "source": [
        "## **Procura e Leitura de arquivos**\n",
        "\n",
        "Foi utilizado o **módulo glob**, para encontrar a partir de um caminho todos os 5285 arquivos que possuem nome que correspondem a um padrão especificado (lat). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWy7XdTrZlM",
        "outputId": "2eba671b-3892-439e-8a78-e906616171a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpWAeCQQWPuv"
      },
      "source": [
        "#Procura todos os arquivos que estão nomeados com 'lat' no caminho especificado\n",
        "arquivos = glob.glob(\"/content/drive/My Drive/TCC/data_mg/lat*.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs_h4RAuWxHT"
      },
      "source": [
        "#Criação da lista para o armazenamento da leitura de cada arquivo\n",
        "arquivos_df = []\n",
        "\n",
        "#Laço de repetição que pega cada arquivo (x) dos arquivos, faz a leitura e armazena na lista (arquivos_df)\n",
        "for x in arquivos:\n",
        "  temp_df = pd.read_csv(x)\n",
        "  arquivos_df.append(temp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KEmzp7Tk-No"
      },
      "source": [
        "arquivos_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4oOsPPwUWj7"
      },
      "source": [
        "## **Conversão de tipo**\n",
        "\n",
        "Cada arquivo possui **duas colunas** importantes: \n",
        "\n",
        "1.   **time:** do tipo string *('xxxx-xx-xx')*, onde possui a data da ETo\n",
        "2.   **ETo:** do tipo float, onde possui o valor da ETo\n",
        "\n",
        "Para melhor manipulação dos dados, foi necessária a **conversão** do **tipo string** da coluna **time** para o **tipo datetime**, e para tal foi utilizado a biblioteca **datetime**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ghFlCJPV5_d"
      },
      "source": [
        "#Criação da lista para armazenar os arquivos em que o tipo da coluna for convertido para datetime\n",
        "arquivos_conv = []\n",
        "\n",
        "#Laço de repetição que pega cada arquivo (a) da lista (arquvios_df), converte o tipo da coluna para datetime de cada um e armazena na lista (arquivos_conv)\n",
        "for a in arquivos_df:\n",
        "  a['time'] = pd.to_datetime(a['time'], format= '%Y-%m-%d')\n",
        "  arquivos_conv.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGoMXhN4lLU3"
      },
      "source": [
        "arquivos_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwn5VrmIXb5Q"
      },
      "source": [
        "## **Exclusão de linhas**\n",
        "\n",
        "Cada arquivo, possui dados que começam de **janeiro de 1980** e vão até a **metade de 2017**. Para melhor tratamento dos dados, foi necessária a **exclusão das linhas** que possuíam dados **do ano de 2017**. Resultando em arquvivos que vão de **janeiro de 1980** até **dezembro de 2016**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EakUjKacZDlv"
      },
      "source": [
        "#Criação da lista para armazenar os arquivos em que o ano de 2017 foi excluído\n",
        "arquivos_sem2017 = []\n",
        "\n",
        "#Laço de repetição que pega cada arquivo (e) da lista (arquivos_conv) e seleciona somente os dados que possuem a data !=2017 e armazena na lista (arquivos_sem2017)\n",
        "for e in arquivos_conv:\n",
        "  result = e[e['time'].dt.year != 2017]\n",
        "  arquivos_sem2017.append(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDE-4AnVlbDN"
      },
      "source": [
        "arquivos_sem2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpDhk4LsKJv"
      },
      "source": [
        "#sem2017_df = pd.concat(arquivos_sem2017, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7GrJ5_Cwkl0"
      },
      "source": [
        "#sem2017_df.to_csv(\"/content/drive/My Drive/TCC/arquivos_sem2017.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16R0SlwoaV5K"
      },
      "source": [
        "## **Cálculo da média**\n",
        "O agrupamento de séries temporais pode apresentar problemas em relação a **alta dimensionalidade**. Dessa forma, reduzir a dimensionalidade é uma técnica importante quando se trabalha com métodos de agrupamento, pois reduz os requisitos de memória e acelera significativamente o cálculo da distância entre os dados brutos. \n",
        "\n",
        "Para tal, foi necessrário calcular a **média da ETo** de cada mês de cada arquivo.\n",
        "\n",
        "*   **Exemplo:** calcular a média do mês de janeiro/fevereiro, etc.\n",
        "\n",
        "Para tal, foi utilizada a função **groupby()** do pandas, onde é possível selecionar grupos iguais (mês de janeiro/fevereiro, etc) de uma coluna específica, que nosso caso é a coluna **'time'** e calcular a média da coluna desejada, que nosso caso é a coluna da **ETo**.\n",
        "\n",
        "E como resultado, foi obtido **12 valores para cada 5285 arquivos**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3D2iUYCccAC"
      },
      "source": [
        "#Criação da lista para armazenar os arquivos em que a média de cada mês foi calculada\n",
        "arquivos_media = []\n",
        "\n",
        "#Laço de repetição que pega cada arquivo (b) da lista (arquivos_sem2017) e calcula a média da ETo para cada mês e armazena na lista (arquivos_media)\n",
        "for b in arquivos_sem2017:\n",
        "  result1 = b.groupby(b.time.dt.month)['ETo'].mean()\n",
        "  arquivos_media.append(result1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SimDb6nGlzno"
      },
      "source": [
        "arquivos_media"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7z-6FAbzsBO"
      },
      "source": [
        "#media_df  = pd.concat(arquivos_media, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqP1uDBfz2M0"
      },
      "source": [
        "#media_df.to_csv(\"/content/drive/My Drive/TCC/arquivos_media.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz1YONO9doK-"
      },
      "source": [
        "## **Normalização Z**\n",
        "A **normalização** é utilizada para corrigir possíveis distorções que os dados brutos podem apresentar. Entre as técnicas para normalizar e modificar séries temporais, a fim de corrigir distorções está a: \n",
        "\n",
        "*  **Normalização Z:** remove imperfeições e diferenças de escala que surgem a partir da geração das séries temporais, sejam estas obtidas por meio de medições ou de algum tipo de transformação de dados.\n",
        "\n",
        "Para normalizar os 12 dados de cada arquivo da base de dados, foi utilizada a função **zscore** da biblioteca **scipy.stats**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4rK-O_DidKs"
      },
      "source": [
        "#Criação da lista para armazenar os arquivos em que a normalização foi aplicada\n",
        "arquivos_zscore = []\n",
        "\n",
        "#Laço de repetição que pega cada arquivo (n) da lista (arquivos_media) e normaliza (zscore) e armazena na lista (arquivos_zscore)\n",
        "for n in arquivos_zscore:\n",
        "  normaliza = zscore(n)\n",
        "  arquivos_zscore.append(normaliza)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmlIqU2DmCuD"
      },
      "source": [
        "arquivos_zscore"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}